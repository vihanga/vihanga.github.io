<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Hugo 0.55.4">
  
  <title>Chapter 4: Model-based Character Animation | Thesis</title>
  
  <link rel="stylesheet" href="/css/thesis-book.css">
  
  
  <link rel="icon" type="image/svg+xml" href="/img/dramatic_v_logo.svg">
  <link rel="apple-touch-icon" href="/img/dramatic_v_logo.svg">
  
  
  <meta property="og:image" content="/img/dramatic_v_logo.svg">
  <meta property="og:image:type" content="image/svg+xml">
  <meta name="twitter:image" content="/img/dramatic_v_logo.svg">
</head>
<body>
  <div class="thesis-wrapper">
    
<div class="thesis-container">
  
  <aside class="thesis-sidebar">
    <div class="thesis-sidebar-content">
      <div class="thesis-logo">
        <img src="/img/dramatic_v_logo.svg" alt="Thesis Logo">
      </div>
      <h3 class="thesis-sidebar-title">Thesis Navigation</h3>
      
      <ul class="thesis-menu">
        <li><a href="/thesis/">← Table of Contents</a></li>
        
        <li class="thesis-menu-section">
          <span class="thesis-menu-section-title">Chapters</span>
          <ul>
            <li><a href="/thesis/chapters/introduction/" >1. Introduction</a></li>
            <li><a href="/thesis/chapters/data-driven-animation/" >2. Data-driven Animation</a></li>
            <li><a href="/thesis/chapters/model-based-rl/" >3. Model-based RL</a></li>
            <li><a href="/thesis/chapters/model-based-animation/" class="active">4. Model-Based Animation</a></li>
            <li><a href="/thesis/chapters/data-driven-rl/" >5. Data-driven RL</a></li>
            <li><a href="/thesis/chapters/latent-dynamics/" >6. Latent Dynamics</a></li>
            <li><a href="/thesis/chapters/conversational-gestures/" >7. Conversational Gestures</a></li>
            <li><a href="/thesis/chapters/conclusion/" >8. Conclusions</a></li>
          </ul>
        </li>
        
        <li class="thesis-menu-section">
          <span class="thesis-menu-section-title">Supplementary</span>
          <ul>
            <li><a href="/thesis/supplementary/c4/">Chapter 4</a></li>
            <li><a href="/thesis/supplementary/c5a/">Chapter 5 - Part A</a></li>
            <li><a href="/thesis/supplementary/c5b/">Chapter 5 - Part B</a></li>
            <li><a href="/thesis/supplementary/c6/">Chapter 6</a></li>
            <li><a href="/thesis/supplementary/c7/">Chapter 7</a></li>
          </ul>
        </li>
        
        <li class="thesis-menu-section">
          <span class="thesis-menu-section-title">Appendices</span>
          <ul>
            <li><a href="/thesis/appendices/a/">A: Serious Games</a></li>
            <li><a href="/thesis/appendices/b/">B: Model-Free RL</a></li>
            <li><a href="/thesis/appendices/c/">C: Supplementary Index</a></li>
            <li><a href="/thesis/appendices/d/">D: Perceptual Evaluation</a></li>
            <li><a href="/thesis/appendices/e/">E: Model-free Results</a></li>
            <li><a href="/thesis/appendices/f/">F: Star Jump Calculation</a></li>
            <li><a href="/thesis/appendices/g/">G: RLAnimate Directory</a></li>
          </ul>
        </li>
      </ul>
      
      <div class="thesis-sidebar-footer">
        <a href="/" class="back-to-main">← Back to Main Site</a>
      </div>
    </div>
  </aside>

  
  <main class="thesis-main">
    <article class="thesis-content">
      <h1>Chapter 4: Model-based Character Animation</h1>
      
      
      

<h1 id="model-based-character-animation">Model-based Character Animation</h1>

<p>This chapter presents exploratory work establishing the feasibility of applying reinforcement learning to dynamic character animation tasks without reliance on physics simulation. The work addresses a fundamental research question: can reinforcement learning effectively control character animation for portraying social behaviours?</p>

<h2 id="motivation-and-objectives">Motivation and Objectives</h2>

<p>Previous work in RL-based animation has relied heavily on physics signals for training, rendering such approaches unsuitable for social behaviours where physics feedback is absent or irrelevant. This chapter establishes a methodology for training agents that achieve three key objectives:</p>

<ul>
<li>Agent functionality relies only on signals relevant to all animation sequences, regardless of the behaviour being portrayed</li>
<li>Multiple types of behaviours can be portrayed by a single agent instance using shared dynamics models</li>
<li>Animation generation occurs dynamically on a frame-by-frame basis, enabling real-time flexibility</li>
</ul>

<h2 id="experimental-approach">Experimental Approach</h2>

<p>The investigation begins with model-free reinforcement learning experiments, following the precedent set by physics-based methods. These initial experiments reveal limitations that motivate the exploration of model-based approaches, which offer the robust sample efficiency demonstrated in supervised learning applications for character animation.</p>

<p>The experiments utilise star jump animations as a test case - a behaviour that requires coordination across multiple joints while remaining sufficiently constrained for systematic analysis. This choice enables focused investigation of the core technical challenges without the confounding factors present in more complex social behaviours.</p>

<h2 id="model-based-learning-results">Model-based Learning Results</h2>

<p>The model-based approach demonstrates several advantages over model-free alternatives:</p>

<ul>
<li><strong>Sample efficiency</strong>: Effective learning from limited motion capture data (5 minutes)</li>
<li><strong>Motion quality</strong>: Generated animations maintain temporal coherence and naturalness</li>
<li><strong>Computational efficiency</strong>: Real-time performance with inference times under 5ms per frame</li>
<li><strong>Implicit regularisation</strong>: The learned dynamics model constrains generated motion to remain within the manifold of human movement</li>
</ul>

<h2 id="key-contributions">Key Contributions</h2>

<p>This chapter establishes that model-based reinforcement learning provides a viable paradigm for character animation without physics simulation. The learned latent dynamics models effectively capture movement patterns from motion capture data, enabling agents to generate novel animations while maintaining human-like qualities.</p>

<p>The primary contribution is the establishment of a basic framework that will be extended in subsequent chapters. This work was published in &ldquo;Learned Dynamics Models and Online Planning for Model-Based Animation Agents&rdquo; at the KES Agents and Multi-Agent Systems 2021 conference.</p>

<h2 id="limitations-and-future-directions">Limitations and Future Directions</h2>

<p>While successful within its scope, this initial work reveals several limitations that motivate subsequent developments:
- Single-behaviour agents lack the flexibility required for interactive applications
- Absence of interaction with physical environments limits applicability
- The framework requires extension to handle more complex social behaviours</p>

<p>These limitations directly inform the development of RLAnimate in Chapter 5, which addresses these constraints through a more sophisticated approach to behaviour representation and multi-task learning.</p>

      
      
      <nav class="thesis-chapter-nav">
        
        <a href="https://vihanga.github.io/thesis/chapters/data-driven-rl/">← Chapter 5: RLAnimate - Data-driven RL for Character Animation</a>
        
        
        
        <a href="https://vihanga.github.io/thesis/chapters/model-based-rl/">Chapter 3: Model-based Reinforcement Learning →</a>
        
      </nav>
    </article>
  </main>
</div>

  </div>
</body>
</html>
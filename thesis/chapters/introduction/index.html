<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Hugo 0.55.4">
  
  <title>Chapter 1: Introduction | Thesis</title>
  
  <link rel="stylesheet" href="/css/thesis-book.css">
  
  
  <link rel="icon" type="image/svg+xml" href="/img/dramatic_v_logo.svg">
  <link rel="apple-touch-icon" href="/img/dramatic_v_logo.svg">
  
  
  <meta property="og:image" content="/img/dramatic_v_logo.svg">
  <meta property="og:image:type" content="image/svg+xml">
  <meta name="twitter:image" content="/img/dramatic_v_logo.svg">
</head>
<body>
  <div class="thesis-wrapper">
    
<div class="thesis-container">
  
  <aside class="thesis-sidebar">
    <div class="thesis-sidebar-content">
      <div class="thesis-logo">
        <img src="/img/dramatic_v_logo.svg" alt="Thesis Logo">
      </div>
      <h3 class="thesis-sidebar-title">Thesis Navigation</h3>
      
      <ul class="thesis-menu">
        <li><a href="/thesis/">← Table of Contents</a></li>
        
        <li class="thesis-menu-section">
          <span class="thesis-menu-section-title">Chapters</span>
          <ul>
            <li><a href="/thesis/chapters/introduction/" class="active">1. Introduction</a></li>
            <li><a href="/thesis/chapters/data-driven-animation/" >2. Data-driven Animation</a></li>
            <li><a href="/thesis/chapters/model-based-rl/" >3. Model-based RL</a></li>
            <li><a href="/thesis/chapters/model-based-animation/" >4. Model-Based Animation</a></li>
            <li><a href="/thesis/chapters/data-driven-rl/" >5. Data-driven RL</a></li>
            <li><a href="/thesis/chapters/latent-dynamics/" >6. Latent Dynamics</a></li>
            <li><a href="/thesis/chapters/conversational-gestures/" >7. Conversational Gestures</a></li>
            <li><a href="/thesis/chapters/conclusion/" >8. Conclusions</a></li>
          </ul>
        </li>
        
        <li class="thesis-menu-section">
          <span class="thesis-menu-section-title">Supplementary</span>
          <ul>
            <li><a href="/thesis/supplementary/c4/">Chapter 4</a></li>
            <li><a href="/thesis/supplementary/c5a/">Chapter 5 - Part A</a></li>
            <li><a href="/thesis/supplementary/c5b/">Chapter 5 - Part B</a></li>
            <li><a href="/thesis/supplementary/c6/">Chapter 6</a></li>
            <li><a href="/thesis/supplementary/c7/">Chapter 7</a></li>
          </ul>
        </li>
        
        <li class="thesis-menu-section">
          <span class="thesis-menu-section-title">Appendices</span>
          <ul>
            <li><a href="/thesis/appendices/a/">A: Serious Games</a></li>
            <li><a href="/thesis/appendices/b/">B: Model-Free RL</a></li>
            <li><a href="/thesis/appendices/c/">C: Supplementary Index</a></li>
            <li><a href="/thesis/appendices/d/">D: Perceptual Evaluation</a></li>
            <li><a href="/thesis/appendices/e/">E: Model-free Results</a></li>
            <li><a href="/thesis/appendices/f/">F: Star Jump Calculation</a></li>
            <li><a href="/thesis/appendices/g/">G: RLAnimate Directory</a></li>
          </ul>
        </li>
      </ul>
      
      <div class="thesis-sidebar-footer">
        <a href="/" class="back-to-main">← Back to Main Site</a>
      </div>
    </div>
  </aside>

  
  <main class="thesis-main">
    <article class="thesis-content">
      <h1>Chapter 1: Introduction</h1>
      
      
      

<h1 id="introduction">Introduction</h1>

<p>This thesis tackles a fundamental challenge in computer animation: how can we create virtual characters that move naturally and responsively without the prohibitive costs of motion capture?</p>

<h2 id="the-problem">The Problem</h2>

<p>Traditional character animation relies heavily on motion capture - an expensive, time-consuming process that requires recording human actors for every possible behavior variation. While this produces high-quality results, it&rsquo;s simply not scalable for interactive applications where characters need to respond dynamically to user input or changing scenarios.</p>

<p>Meanwhile, existing alternatives have significant limitations. Supervised learning methods can generate animations but lack flexibility. Physics-based reinforcement learning works brilliantly for athletic movements but fails for social behaviors like gestures - there&rsquo;s no physics simulation to tell us if a wave looks &ldquo;friendly&rdquo; or a gesture feels &ldquo;natural.&rdquo;</p>

<h2 id="my-approach">My Approach</h2>

<p>I developed RLAnimate, a framework that fundamentally rethinks how we approach character animation. Instead of using reward functions (the traditional RL approach), I use motion capture data as learning objectives. This allows agents to learn what &ldquo;human-like&rdquo; means directly from examples, while maintaining the flexibility and responsiveness that makes RL powerful.</p>

<p>The key insight is treating animation as a model-based reinforcement learning problem where agents learn the dynamics of human movement. By understanding how joint rotations create behaviors, agents can generate novel animations that look natural while adapting to changing requirements in real-time.</p>

<h2 id="key-contributions">Key Contributions</h2>

<ol>
<li><strong>A new paradigm for animation RL</strong> - Using motion capture data as objectives rather than rewards</li>
<li><strong>Multi-behavior agents</strong> - Single agents that can wave, point, and generate conversational gestures</li>
<li><strong>Technical innovations</strong> - Quaternion neural networks, realism regularization, and hierarchical dynamics models</li>
<li><strong>Proven results</strong> - Animations that are statistically indistinguishable from human motion capture</li>
</ol>

<h2 id="research-questions">Research Questions</h2>

<p>The thesis systematically addresses four key questions:
- Can RL work for animation without physics? (Yes - through latent dynamics learning)
- Can we make it human-like? (Yes - using motion capture as objectives)
- How do we handle complexity like fingers? (Quaternions + dedicated animation dynamics)
- Can it work for conversational gestures? (Yes - with realism regularization)</p>

<h2 id="thesis-journey">Thesis Journey</h2>

<p>The work progresses from establishing basic feasibility (Chapter 4) through developing the core RLAnimate methodology (Chapter 5), extending to complex movements with fingers (Chapter 6), and culminating in conversational beat gestures that match human quality (Chapter 7).</p>

      
      
      <nav class="thesis-chapter-nav">
        
        <a href="https://vihanga.github.io/thesis/chapters/data-driven-animation/">← Chapter 2: Virtual Character Animation and Perception</a>
        
        
        
        <span></span>
        
      </nav>
    </article>
  </main>
</div>

  </div>
</body>
</html>
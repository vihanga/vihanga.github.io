<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.1.1">
  <meta name="generator" content="Hugo 0.55.4" />
  <meta name="author" content="Vihanga Gamage">

  
  
  
  
    
  
  <meta name="description" content="Video Demonstrations Latent Space Visualization  Motion Embeddings: t-SNE and PCA visualizations of learned representations Interpolation Results: Smooth transitions between different motion styles Latent Dynamics: Evolution of latent codes during motion sequences Disentanglement: Independent control of motion factors  Generative Results  Novel motion synthesis from latent codes Style transfer between characters Motion completion and in-betweening Multi-modal motion generation  Additional Results Quantitative Evaluation    Model Variant Reconstruction Error Latent Dim Disentanglement Score FID Score     VAE 0.">

  
  <link rel="alternate" hreflang="en-us" href="https://vihanga.github.io/thesis/supplementary/c6/">

  


  

  

  

  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="https://vihanga.github.io/index.xml" type="application/rss+xml" title="Vihanga Gamage&#39;s Corner of the World Wide Web">
  <link rel="feed" href="https://vihanga.github.io/index.xml" type="application/rss+xml" title="Vihanga Gamage&#39;s Corner of the World Wide Web">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://vihanga.github.io/thesis/supplementary/c6/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@VihGamage">
  <meta property="twitter:creator" content="@VihGamage">
  
  <meta property="og:site_name" content="Vihanga Gamage&#39;s Corner of the World Wide Web">
  <meta property="og:url" content="https://vihanga.github.io/thesis/supplementary/c6/">
  <meta property="og:title" content="Chapter 6: Supplementary Material | Vihanga Gamage&#39;s Corner of the World Wide Web">
  <meta property="og:description" content="Video Demonstrations Latent Space Visualization  Motion Embeddings: t-SNE and PCA visualizations of learned representations Interpolation Results: Smooth transitions between different motion styles Latent Dynamics: Evolution of latent codes during motion sequences Disentanglement: Independent control of motion factors  Generative Results  Novel motion synthesis from latent codes Style transfer between characters Motion completion and in-betweening Multi-modal motion generation  Additional Results Quantitative Evaluation    Model Variant Reconstruction Error Latent Dim Disentanglement Score FID Score     VAE 0.">
  
  
    
  <meta property="og:image" content="https://vihanga.github.io/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2025-01-22T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2025-01-22T00:00:00&#43;00:00">
  

  

  

  <title>Chapter 6: Supplementary Material | Vihanga Gamage&#39;s Corner of the World Wide Web</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Vihanga Gamage&#39;s Corner of the World Wide Web</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#research">
            
            <span>Research</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#blog">
            
            <span>Blog</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#chess">
            
            <span>Chess</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Contact/Calendar</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/thesis/">
            
            <span>Thesis</span>
            
          </a>
        </li>

        
        

      

        

        
      </ul>

    </div>
  </div>
</nav>


<link rel="stylesheet" href="/css/thesis-book.css">

<div class="thesis-container">
  
  <aside class="thesis-sidebar">
    <div class="thesis-sidebar-content">
      <h3 class="thesis-sidebar-title">Navigation</h3>
      
      <ul class="thesis-menu">
        <li><a href="/thesis/">Home</a></li>
        
        <li class="thesis-menu-section">
          <span class="thesis-menu-section-title">Chapters</span>
          <ul>
            <li><a href="/thesis/chapters/introduction/">1. Introduction</a></li>
            <li><a href="/thesis/chapters/data-driven-animation/">2. Data-driven Animation</a></li>
            <li><a href="/thesis/chapters/model-based-rl/">3. Model-based RL</a></li>
            <li><a href="/thesis/chapters/model-based-animation/">4. Model-Based Animation</a></li>
            <li><a href="/thesis/chapters/data-driven-rl/">5. Data-driven RL</a></li>
            <li><a href="/thesis/chapters/latent-dynamics/">6. Latent Dynamics</a></li>
            <li><a href="/thesis/chapters/conversational-gestures/">7. Conversational Gestures</a></li>
            <li><a href="/thesis/chapters/conclusion/">8. Conclusions</a></li>
          </ul>
        </li>
        
        <li class="thesis-menu-section">
          <span class="thesis-menu-section-title">Supplementary</span>
          <ul>
            <li><a href="/thesis/supplementary/c4/">Chapter 4</a></li>
            <li><a href="/thesis/supplementary/c5a/">Chapter 5 - Part A</a></li>
            <li><a href="/thesis/supplementary/c5b/">Chapter 5 - Part B</a></li>
            <li><a href="/thesis/supplementary/c6/">Chapter 6</a></li>
            <li><a href="/thesis/supplementary/c7/">Chapter 7</a></li>
          </ul>
        </li>
        
        <li class="thesis-menu-section">
          <span class="thesis-menu-section-title">Appendices</span>
          <ul>
            <li><a href="/thesis/appendices/a/">A: Serious Games</a></li>
            <li><a href="/thesis/appendices/b/">B: Model-Free RL</a></li>
            <li><a href="/thesis/appendices/c/">C: Supplementary Index</a></li>
            <li><a href="/thesis/appendices/d/">D: Perceptual Evaluation</a></li>
            <li><a href="/thesis/appendices/e/">E: Model-free Results</a></li>
            <li><a href="/thesis/appendices/f/">F: Star Jump Calculation</a></li>
            <li><a href="/thesis/appendices/g/">G: RLAnimate Directory</a></li>
          </ul>
        </li>
      </ul>
    </div>
  </aside>

  
  <main class="thesis-main">
    <article class="thesis-content">
      <h1>Chapter 6: Supplementary Material</h1>
      
      
      

<h2 id="video-demonstrations">Video Demonstrations</h2>

<h3 id="latent-space-visualization">Latent Space Visualization</h3>

<ul>
<li><strong>Motion Embeddings</strong>: t-SNE and PCA visualizations of learned representations</li>
<li><strong>Interpolation Results</strong>: Smooth transitions between different motion styles</li>
<li><strong>Latent Dynamics</strong>: Evolution of latent codes during motion sequences</li>
<li><strong>Disentanglement</strong>: Independent control of motion factors</li>
</ul>

<h3 id="generative-results">Generative Results</h3>

<ul>
<li>Novel motion synthesis from latent codes</li>
<li>Style transfer between characters</li>
<li>Motion completion and in-betweening</li>
<li>Multi-modal motion generation</li>
</ul>

<h2 id="additional-results">Additional Results</h2>

<h3 id="quantitative-evaluation">Quantitative Evaluation</h3>

<table>
<thead>
<tr>
<th>Model Variant</th>
<th>Reconstruction Error</th>
<th>Latent Dim</th>
<th>Disentanglement Score</th>
<th>FID Score</th>
</tr>
</thead>

<tbody>
<tr>
<td>VAE</td>
<td>0.082</td>
<td>128</td>
<td>0.72</td>
<td>45.3</td>
</tr>

<tr>
<td>β-VAE</td>
<td>0.091</td>
<td>128</td>
<td>0.85</td>
<td>48.1</td>
</tr>

<tr>
<td>VQ-VAE</td>
<td>0.075</td>
<td>512 codes</td>
<td>0.68</td>
<td>42.7</td>
</tr>

<tr>
<td>Proposed</td>
<td>0.071</td>
<td>64</td>
<td>0.89</td>
<td>38.2</td>
</tr>
</tbody>
</table>

<h3 id="ablation-studies">Ablation Studies</h3>

<ul>
<li>Impact of latent dimensionality</li>
<li>Different regularization strategies</li>
<li>Architecture choices for encoder/decoder</li>
<li>Training objective variations</li>
</ul>

<h3 id="generalization-analysis">Generalization Analysis</h3>

<ul>
<li>Cross-dataset performance</li>
<li>Different skeleton configurations</li>
<li>Unseen motion categories</li>
<li>Temporal extrapolation</li>
</ul>

<h2 id="code-examples">Code Examples</h2>

<h3 id="variational-autoencoder-architecture">Variational Autoencoder Architecture</h3>

<pre><code class="language-python">class MotionVAE(nn.Module):
    def __init__(self, input_dim, latent_dim, hidden_dims=[512, 256]):
        super().__init__()
        self.latent_dim = latent_dim
        
        # Encoder
        encoder_layers = []
        in_dim = input_dim
        for h_dim in hidden_dims:
            encoder_layers.extend([
                nn.Linear(in_dim, h_dim),
                nn.ReLU(),
                nn.BatchNorm1d(h_dim)
            ])
            in_dim = h_dim
        
        self.encoder = nn.Sequential(*encoder_layers)
        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)
        self.fc_var = nn.Linear(hidden_dims[-1], latent_dim)
        
        # Decoder
        decoder_layers = []
        hidden_dims.reverse()
        in_dim = latent_dim
        for h_dim in hidden_dims:
            decoder_layers.extend([
                nn.Linear(in_dim, h_dim),
                nn.ReLU(),
                nn.BatchNorm1d(h_dim)
            ])
            in_dim = h_dim
        
        self.decoder = nn.Sequential(*decoder_layers)
        self.final_layer = nn.Linear(hidden_dims[-1], input_dim)
        
    def encode(self, x):
        h = self.encoder(x)
        return self.fc_mu(h), self.fc_var(h)
    
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        h = self.decoder(z)
        return self.final_layer(h)
    
    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar
</code></pre>

<h3 id="latent-dynamics-model">Latent Dynamics Model</h3>

<pre><code class="language-python">class LatentDynamics(nn.Module):
    def __init__(self, latent_dim, action_dim, hidden_dim=256):
        super().__init__()
        self.dynamics_net = nn.Sequential(
            nn.Linear(latent_dim + action_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, latent_dim)
        )
        
        # Learned prior for regularization
        self.prior_net = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, latent_dim * 2)  # mu and logvar
        )
    
    def forward(self, z_t, a_t):
        &quot;&quot;&quot;Predict next latent state given current state and action&quot;&quot;&quot;
        z_next = self.dynamics_net(torch.cat([z_t, a_t], dim=-1))
        return z_t + z_next  # Residual connection
    
    def get_prior(self, z_t):
        &quot;&quot;&quot;Compute prior distribution for next state&quot;&quot;&quot;
        prior_params = self.prior_net(z_t)
        mu, logvar = torch.chunk(prior_params, 2, dim=-1)
        return mu, logvar
</code></pre>

<h3 id="training-pipeline">Training Pipeline</h3>

<pre><code class="language-python">def train_latent_model(model, dynamics_model, dataloader, epochs=100):
    optimizer = torch.optim.Adam(
        list(model.parameters()) + list(dynamics_model.parameters()),
        lr=1e-3
    )
    
    for epoch in range(epochs):
        for batch in dataloader:
            motion_sequence = batch['motion']  # Shape: (B, T, D)
            
            # Encode entire sequence
            latent_sequence = []
            for t in range(motion_sequence.size(1)):
                mu, logvar = model.encode(motion_sequence[:, t])
                z = model.reparameterize(mu, logvar)
                latent_sequence.append(z)
            
            latent_sequence = torch.stack(latent_sequence, dim=1)
            
            # Reconstruction loss
            recon_loss = 0
            for t in range(motion_sequence.size(1)):
                recon = model.decode(latent_sequence[:, t])
                recon_loss += F.mse_loss(recon, motion_sequence[:, t])
            
            # Dynamics loss
            dynamics_loss = 0
            for t in range(motion_sequence.size(1) - 1):
                z_pred = dynamics_model(latent_sequence[:, t], batch['actions'][:, t])
                dynamics_loss += F.mse_loss(z_pred, latent_sequence[:, t + 1])
            
            # KL divergence for VAE
            kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
            
            # Total loss
            loss = recon_loss + 0.1 * dynamics_loss + 0.001 * kl_loss
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
</code></pre>

<h2 id="dataset-information">Dataset Information</h2>

<h3 id="motion-sequences-used">Motion Sequences Used</h3>

<ul>
<li><strong>CMU MoCap</strong>: 2,500 sequences covering 100+ motion types</li>
<li><strong>Human3.6M</strong>: 3.6 million frames of daily activities</li>
<li><strong>Custom Dance Dataset</strong>: 500 professional dance sequences</li>
<li><strong>Sports Motion Library</strong>: 1,000 athletic movement clips</li>
</ul>

<h3 id="data-preprocessing">Data Preprocessing</h3>

<pre><code class="language-python"># Motion data normalization pipeline
def preprocess_motion_sequences(raw_data):
    # Global position normalization
    normalized = normalize_root_position(raw_data)
    
    # Velocity and acceleration features
    velocities = compute_finite_differences(normalized, order=1)
    accelerations = compute_finite_differences(normalized, order=2)
    
    # Joint angle representation
    joint_angles = forward_kinematics_to_angles(normalized)
    
    # Combine features
    features = np.concatenate([
        normalized,
        velocities * 0.1,  # Scale velocities
        accelerations * 0.01,  # Scale accelerations
        joint_angles
    ], axis=-1)
    
    return features
</code></pre>

<h3 id="evaluation-protocols">Evaluation Protocols</h3>

<ol>
<li><p><strong>Reconstruction Quality</strong></p>

<ul>
<li>Per-joint position error</li>
<li>Velocity matching</li>
<li>Foot sliding artifacts</li>
<li>Motion smoothness</li>
</ul></li>

<li><p><strong>Latent Space Quality</strong></p>

<ul>
<li>Interpolation smoothness</li>
<li>Disentanglement metrics</li>
<li>Coverage and diversity</li>
<li>Clustering quality</li>
</ul></li>
</ol>

<h2 id="computational-resources">Computational Resources</h2>

<h3 id="training-infrastructure">Training Infrastructure</h3>

<ul>
<li><strong>GPU</strong>: 4x NVIDIA A100 (40GB)</li>
<li><strong>Training Time</strong>: 72 hours for full model</li>
<li><strong>Batch Size</strong>: 256 sequences</li>
<li><strong>Memory Usage</strong>: ~35GB GPU memory</li>
</ul>

<h3 id="inference-performance">Inference Performance</h3>

<table>
<thead>
<tr>
<th>Operation</th>
<th>Time (ms)</th>
<th>Memory (MB)</th>
</tr>
</thead>

<tbody>
<tr>
<td>Encode</td>
<td>0.8</td>
<td>45</td>
</tr>

<tr>
<td>Decode</td>
<td>1.2</td>
<td>52</td>
</tr>

<tr>
<td>Dynamics Step</td>
<td>0.3</td>
<td>18</td>
</tr>

<tr>
<td>Full Pipeline</td>
<td>2.5</td>
<td>120</td>
</tr>
</tbody>
</table>

<h2 id="supplementary-figures">Supplementary Figures</h2>

<h3 id="latent-space-analysis">Latent Space Analysis</h3>

<ul>
<li>Distribution of learned codes</li>
<li>Principal components visualization</li>
<li>Trajectory analysis in latent space</li>
<li>Correlation with semantic attributes</li>
</ul>

<h3 id="architecture-variants">Architecture Variants</h3>

<ul>
<li>Different encoder/decoder architectures</li>
<li>Skip connections impact</li>
<li>Attention mechanisms</li>
<li>Temporal modeling choices</li>
</ul>

<h2 id="advanced-applications">Advanced Applications</h2>

<h3 id="motion-editing-interface">Motion Editing Interface</h3>

<pre><code class="language-python">class LatentMotionEditor:
    def __init__(self, vae_model):
        self.model = vae_model
        self.attribute_directions = self.learn_attribute_directions()
    
    def edit_motion(self, motion, attribute, strength):
        &quot;&quot;&quot;Edit motion by manipulating latent codes&quot;&quot;&quot;
        # Encode to latent space
        z, _ = self.model.encode(motion)
        
        # Apply attribute direction
        direction = self.attribute_directions[attribute]
        z_edited = z + strength * direction
        
        # Decode back to motion
        edited_motion = self.model.decode(z_edited)
        
        return edited_motion
    
    def interpolate(self, motion1, motion2, alpha):
        &quot;&quot;&quot;Smooth interpolation between motions&quot;&quot;&quot;
        z1, _ = self.model.encode(motion1)
        z2, _ = self.model.encode(motion2)
        
        # Spherical linear interpolation
        z_interp = slerp(z1, z2, alpha)
        
        return self.model.decode(z_interp)
</code></pre>

<h3 id="real-time-applications">Real-time Applications</h3>

<ul>
<li>Interactive motion synthesis</li>
<li>Online motion compression</li>
<li>Latent space control interfaces</li>
<li>Motion prediction and completion</li>
</ul>

<hr />

<p><em>Code and trained models available at the project repository. Contact for dataset access.</em></p>

      
      
      <nav class="thesis-chapter-nav">
        
        <a href="https://vihanga.github.io/thesis/supplementary/c7/">← Chapter 7: Supplementary Material</a>
        
        
        
        <a href="https://vihanga.github.io/thesis/supplementary/c5b/">Chapter 5b: Supplementary Material →</a>
        
      </nav>
    </article>
  </main>
</div>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "Search Results",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    <script src="/js/academic.min.2861db6bcf2db4b5eade32c795453e47.js"></script>

    

  </body>
</html>
